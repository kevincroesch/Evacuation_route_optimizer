{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T21:49:23.404759Z",
     "start_time": "2019-07-30T21:49:17.523170Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    }
   ],
   "source": [
    "#data stuff\n",
    "import pandas as pd\n",
    "\n",
    "#Modelling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "#other\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T17:56:41.389032Z",
     "start_time": "2019-07-26T17:56:41.354080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fl511 = pd.read_csv('./Datasets/lastweek_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T22:40:57.119025Z",
     "start_time": "2019-07-25T22:40:57.113040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fl511.drop(columns=['User', 'User_ID', 'Geo', 'HashTag'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T23:01:12.326444Z",
     "start_time": "2019-07-25T23:01:12.320391Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_url(tweet):\n",
    "    ind = tweet.find('fl511.com')\n",
    "    tweet = tweet[:ind]\n",
    "    return tweet\n",
    "def remove_time(tweet):\n",
    "    ind = tweet.rfind('at')\n",
    "    tweet = tweet[:ind]\n",
    "    return tweet\n",
    "def remove_inc(tweet):\n",
    "    ind = tweet.find(' on ')\n",
    "    tweet = tweet[ind+4:]\n",
    "    if ' on ' in tweet:\n",
    "        ind = tweet.find(' on ')\n",
    "        tweet = tweet[ind+4:]\n",
    "    return tweet\n",
    "def remove_tail(tweet):\n",
    "    ind = tweet.rfind(',')\n",
    "    tweet = tweet[:ind]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T23:01:13.509656Z",
     "start_time": "2019-07-25T23:01:13.473100Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fl511 = pd.read_csv('./Datasets/lastweek_y.csv')\n",
    "fl511['Tweet'] = fl511['Tweet'].map(remove_url)\n",
    "fl511['Tweet'] = fl511['Tweet'].map(remove_time)\n",
    "fl511['Tweet'] = fl511['Tweet'].map(remove_inc)\n",
    "fl511['Tweet'] = fl511['Tweet'].map(remove_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T23:18:42.463171Z",
     "start_time": "2019-07-25T23:18:42.440724Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'826 Express south',\n",
       " '826 Express south ramp',\n",
       " '95 Express north',\n",
       " '95 Express north ramp',\n",
       " '95 Express south',\n",
       " '95 Express south ramp',\n",
       " 'Alton Rd',\n",
       " 'Bird Rd',\n",
       " 'Bridge Rd/Star Island',\n",
       " 'Caribbean Blvd',\n",
       " 'Florida Turnpike',\n",
       " \"Florida's Turnpike/SR-826\",\n",
       " 'Floridas Turnpike north',\n",
       " 'Floridas Turnpike north ramp',\n",
       " 'Floridas Turnpike south',\n",
       " 'Floridas Turnpike south ramp',\n",
       " 'Fountain St/Palm Island',\n",
       " 'Golden Glades Park & Ride',\n",
       " 'I-195 East - Miami Beach/SR-112 West - Airport',\n",
       " 'I-195 east',\n",
       " 'I-195 east ramp',\n",
       " 'I-195 west',\n",
       " 'I-195 west ramp',\n",
       " 'I-395 east',\n",
       " 'I-395 east ramp',\n",
       " 'I-395 west',\n",
       " 'I-75',\n",
       " 'I-75 north',\n",
       " 'I-75 south',\n",
       " 'I-75 south ramp',\n",
       " 'I-75 to',\n",
       " 'I-95',\n",
       " 'I-95 Mainline/Golden Glades Interchange',\n",
       " 'I-95 Mainline/I-395',\n",
       " 'I-95 Mainline/Ives Dairy Rd',\n",
       " 'I-95 North',\n",
       " 'I-95 South',\n",
       " 'I-95 north',\n",
       " 'I-95 north ramp',\n",
       " 'I-95 south',\n",
       " 'I-95 south ramp',\n",
       " 'Le Jeune Rd',\n",
       " 'Le Jeune Rd North',\n",
       " 'Le Jeune Rd North and traffic backed up until NW 57 Ave',\n",
       " 'Lejeune Rd',\n",
       " 'Lejeune Rd/NW 45 Ave',\n",
       " 'MacArthur Causeway east',\n",
       " 'MacArthur Causeway east ramp',\n",
       " 'MacArthur Causeway west',\n",
       " 'Macarthur Causeway',\n",
       " 'Miller Dr/SW 56 St',\n",
       " 'NE 203 St/Ives Dairy Rd',\n",
       " 'NW 107 Ave',\n",
       " 'NW 12 Ave',\n",
       " 'NW 122 St',\n",
       " 'NW 137 Ave',\n",
       " 'NW 137 Ave Southbound',\n",
       " 'NW 151 St',\n",
       " 'NW 154 St',\n",
       " 'NW 154 St /Miami Lakes Dr',\n",
       " 'NW 154 St/Miami Lakes Dr',\n",
       " 'NW 17 Ave',\n",
       " 'NW 17 Ave. Last updated',\n",
       " 'NW 17 Ave/NW 12 Ave',\n",
       " 'NW 17 Ave/NW 22 Ave',\n",
       " 'NW 17th Ave Northbound',\n",
       " 'NW 22 Ave',\n",
       " 'NW 25 St',\n",
       " 'NW 27 Ave',\n",
       " 'NW 32 Ave',\n",
       " 'NW 36 St',\n",
       " 'NW 37 Ave Merge West/NW 167 St',\n",
       " 'NW 37 Ave/Douglas Rd',\n",
       " 'NW 39 St/NW 10 Ave',\n",
       " 'NW 45 Ave',\n",
       " 'NW 47 Ave',\n",
       " 'NW 57 Ave',\n",
       " 'NW 57 Ave to',\n",
       " 'NW 57 Ave, off-ramp closed',\n",
       " 'NW 58 St',\n",
       " 'NW 62 St/Dr. Martin Luther King Jr. Blvd',\n",
       " 'NW 62 St/Dr. Martin Luther King...http:',\n",
       " 'NW 67 Ave/Ludlam Rd',\n",
       " 'NW 67 Ave/Ludlam Rd Merge West/NW 167 St',\n",
       " 'NW 69 St',\n",
       " 'NW 72 Ave',\n",
       " 'NW 74 St',\n",
       " 'NW 81 St',\n",
       " 'NW 87 Ave',\n",
       " 'NW 95 St/Rev Dr. A. Jackson Jr. Blvd',\n",
       " 'North Miami/Bal Harbour/NW 125 St',\n",
       " 'Okeechobee Rd',\n",
       " 'Port Miami Tunnel east ramp',\n",
       " 'Port Miami Tunnel west ramp',\n",
       " 'Quail Roost Dr to',\n",
       " 'Riviera Dr',\n",
       " 'SR 826',\n",
       " 'SR 826/NW 67 Ave',\n",
       " 'SR 874',\n",
       " 'SR 878 East',\n",
       " 'SR-112',\n",
       " 'SR-112 West/Miami Inter',\n",
       " 'SR-112 West/Miami International Airport',\n",
       " 'SR-112 east',\n",
       " 'SR-112 east ramp',\n",
       " 'SR-112 west',\n",
       " 'SR-823/NW 57 Ave/Red Rd',\n",
       " 'SR-823/Red Rd/NW 57 Ave',\n",
       " 'SR-826 east',\n",
       " 'SR-826 east ramp',\n",
       " 'SR-826 north',\n",
       " 'SR-826 north ramp',\n",
       " 'SR-826 south',\n",
       " 'SR-826 south ramp',\n",
       " 'SR-826 west',\n",
       " 'SR-826 west ramp',\n",
       " 'SR-836',\n",
       " 'SR-836 East',\n",
       " 'SR-836 east',\n",
       " 'SR-836 east ramp',\n",
       " 'SR-836 west',\n",
       " 'SR-836 west ramp',\n",
       " 'SR-836/NW 72 Ave',\n",
       " 'SR-860/Miami Gardens Dr',\n",
       " 'SR-874 north',\n",
       " 'SR-874 south',\n",
       " 'SR-878 west',\n",
       " 'SR-886/Port Boulevard',\n",
       " 'SR-907/Alton Rd',\n",
       " 'SR-916/NW 135 St/Opa-locka Blvd',\n",
       " 'SR-924 east',\n",
       " 'SR-924 west',\n",
       " 'SR-924/NW 119 St',\n",
       " 'SR-932/NW 103 St',\n",
       " 'SR-934/NW 74 St',\n",
       " 'SR-934/NW 79 St/NW 81 St',\n",
       " 'SR-953/Le Jeune Rd/SW 42 Ave',\n",
       " 'SR-968/West Flagler St',\n",
       " 'SR-973/SW 132 St',\n",
       " 'SR-976/Bird Rd/SW 40 St',\n",
       " 'SR-976/SW 40 St/Bird Rd',\n",
       " 'SW 17 Ave',\n",
       " 'SW 24 St/Coral Way',\n",
       " 'SW 344 St/SR-9336/Palm Dr',\n",
       " 'SW 40 St East',\n",
       " 'SW 62 Ave',\n",
       " 'SW 88 St',\n",
       " 'SW 88 St West',\n",
       " 'Terminal Isle',\n",
       " 'Turnpike',\n",
       " 'US 27/Okeechobee Rd/S River Dr',\n",
       " 'US-1 Junction',\n",
       " 'US-1 north',\n",
       " 'US-1 south',\n",
       " 'US-27/Okeechobee Rd/South River Dr',\n",
       " 'US-41/SW 8 St',\n",
       " 'US-41/SW 8 St East',\n",
       " 'US-41/SW 8 St West',\n",
       " 'US-41/Tamiami Trail/SW 8 St',\n",
       " 'US-41/Tamiami Trail/SW 8 St and traffic backed up until SR-976/SW 40 St/Bird Rd',\n",
       " 'before I-75 to',\n",
       " 'beyond NW 57 Ave to',\n",
       " 'beyond Quail Roost Dr to'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roads = set()\n",
    "for tweet in fl511['Tweet']:\n",
    "    join_words = [' to ', ' before ', ' beyond ', ' at ', ' from ']\n",
    "    easy = True\n",
    "    if len(tweet) == 0:\n",
    "        easy=False\n",
    "    for stop in join_words:\n",
    "        if stop in tweet:\n",
    "            easy=False\n",
    "    if  easy == True:\n",
    "        roads.add(tweet)\n",
    "    for join in join_words:\n",
    "        ind = tweet.find(join)\n",
    "        if ind != -1:\n",
    "            loc1 = tweet[:ind]\n",
    "            if 'from' not in loc1:\n",
    "                roads.add(loc1)\n",
    "            loc2 = tweet[ind + len(join):]\n",
    "            if 'Exit' not in loc2:\n",
    "                roads.add(loc2)\n",
    "        #roads.add(loc2)\n",
    "roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T23:21:14.226284Z",
     "start_time": "2019-07-25T23:21:14.133575Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets_20 = pd.read_csv('./Datasets/lastweek_X_20000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T17:56:51.990728Z",
     "start_time": "2019-07-26T17:56:51.964830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fl511 = pd.read_csv('./Datasets/lastweek_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T18:28:55.761159Z",
     "start_time": "2019-07-26T18:28:55.758085Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "expr = '[A-Z]+\\-\\d+|[a-zA-z]+|[A-Z][a-zA-Z]+\\s\\d{1,3}[A-Z]*|\\d{1,3}\\W[A-Z][a-zA-Z]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T19:03:30.059556Z",
     "start_time": "2019-07-26T19:03:30.054568Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i-85']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'i-85'\n",
    "\n",
    "card = re.compile(r'(?:\\d{1,4}|[A-Z][a-z]+\\W|[A-Za-z]+\\-\\d+){1,3}')\n",
    "re.findall(card, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T16:28:29.926071Z",
     "start_time": "2019-07-30T16:27:49.936080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4542b6b375cb4c1594b3f4c5437bc31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=80000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18577000f7114c9f86042f5e20db1592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Datasets/timeloop_2019-07-23.csv')\n",
    "data.drop(columns=['User','User_ID','Geo'], inplace = True)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Date'] = data.assign(Date=data['Date'].dt.round('H'))['Date']\n",
    "times = []\n",
    "times.append(data['Date'][0])\n",
    "\n",
    "for i in tqdm_notebook(data.index):\n",
    "    time = data['Date'][i]\n",
    "    if time != times[len(times)-1]:\n",
    "        times.append(time)\n",
    "        \n",
    "dic = {'time': [], 'tweets': []}\n",
    "\n",
    "for hour in tqdm_notebook(times):\n",
    "    total = ''\n",
    "    tweets = list(data[data['Date'] == hour]['Tweet'])\n",
    "    for twit in tweets:\n",
    "        total += str(twit)\n",
    "    dic['time'].append(hour)\n",
    "    dic['tweets'].append(total)\n",
    "data2 = pd.DataFrame.from_dict(dic)\n",
    "\n",
    "data2.set_index('time', inplace=True)\n",
    "data2.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T17:57:25.498140Z",
     "start_time": "2019-07-30T17:57:25.443562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-22 11:00:00+00:00</th>\n",
       "      <td>Lmaoo wah kinda stress thisOjala algun puto di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-22 12:00:00+00:00</th>\n",
       "      <td>REAR VIEW (Intro) - Hell Storm @Greater Downto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-22 13:00:00+00:00</th>\n",
       "      <td>Welp. pic.twitter.com/kiRmEMKoGTYou are beginn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-22 14:00:00+00:00</th>\n",
       "      <td>EFE: Pedro Sánchez aborda plan de gobierno en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-22 15:00:00+00:00</th>\n",
       "      <td>About yesterday. 1st to Brunch at #latinhouseg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      tweets\n",
       "time                                                                        \n",
       "2019-07-22 11:00:00+00:00  Lmaoo wah kinda stress thisOjala algun puto di...\n",
       "2019-07-22 12:00:00+00:00  REAR VIEW (Intro) - Hell Storm @Greater Downto...\n",
       "2019-07-22 13:00:00+00:00  Welp. pic.twitter.com/kiRmEMKoGTYou are beginn...\n",
       "2019-07-22 14:00:00+00:00  EFE: Pedro Sánchez aborda plan de gobierno en ...\n",
       "2019-07-22 15:00:00+00:00  About yesterday. 1st to Brunch at #latinhouseg..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:00:48.938108Z",
     "start_time": "2019-07-29T18:00:48.928062Z"
    }
   },
   "outputs": [],
   "source": [
    "closed = pd.read_csv('Datasets/manual_y.csv')\n",
    "closed.rename({'Unnamed: 0': 'Date'}, axis=1, inplace=True)\n",
    "closed['Date'] = pd.to_datetime(closed['Date'])\n",
    "closed.set_index('Date', inplace=True)\n",
    "closed.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Word Vec (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T17:47:02.802075Z",
     "start_time": "2019-07-29T17:44:45.400910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:/Users/steph/Downloads/lexvec.enwiki+newscrawl.300d.W.pos.vectors/lexvec.enwiki+newscrawl.300d.W.pos.vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-29T17:39:35.380Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "# from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# #replace with own corpus later\n",
    "# import gensim.downloader as api\n",
    "# corpus = api.load('text8')\n",
    "\n",
    "# # Train a model! \n",
    "# model = Word2Vec(corpus,      # Corpus of data.\n",
    "#                  size=100,    # How many dimensions do you want in your word vector?\n",
    "#                  window=5,    # How many \"context words\" do you want?\n",
    "#                  min_count=1, # Ignores words below this threshold.\n",
    "#                  sg=0,        # SG = 1 uses SkipGram, SG = 0 uses CBOW (default).\n",
    "#                  workers=2)   # Number of \"worker threads\" to use (parallelizes process)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T17:54:11.942341Z",
     "start_time": "2019-07-29T17:54:11.938352Z"
    }
   },
   "outputs": [],
   "source": [
    "#only for one road at the moment\n",
    "X = data2\n",
    "y = closed[''] #column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#framework for multiple models, untested\n",
    "for road_i in range(closed.shape[1]):\n",
    "    exec(f'X_train_{i}, X_test_{i}, y_train_{i}, y_test_{i}, train_test_split(X, y={closed[closed.columns[i]]}, stratify={closed[closed.columns[i]]}, random_state=42)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer(token_pattern='[a-zA-z]+ | [A-Za-z]+\\-*\\d+\\W(?:[sS]outh|[Nn]orth|East|West|[NSEW]{1,2}|[nswe]{1,2})*')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "pipe_params = {\n",
    "    'vec__stop_words': [custom, 'english'],\n",
    "    'vec__max_features': [12000],\n",
    "    'vec__min_df': [1, 2],\n",
    "    'vec__max_df': [.9],\n",
    "    'vec__ngram_range': [(3,5),(3,7)],\n",
    "    'nb__alpha': [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T18:12:34.177103Z",
     "start_time": "2019-07-29T18:12:34.161772Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-76adf74b7c1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipe_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cvs:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print('cvs:', gs.best_score_)\n",
    "print('train score:', gs.score(X_train, y_train))\n",
    "print('test score:', gs.score(X_test, y_test))\n",
    "gs.best_params_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#framework for multiple models\n",
    "for road_i in range(closed.shape[1]):\n",
    "    exec(f'gs_{i} = GridSearchCV(pipe, param_grid=pipe_params, cv=5)')\n",
    "    exec(f'gs_{i}.fit(X_train_{i}, y_train_{i})')\n",
    "    \n",
    "score = 0\n",
    "for road_i in range(closed.shape[1]):\n",
    "    score += exec(f'gs_{i}.score(X_test_{i}, y_test_{i})')\n",
    "score = score / closed.shape[1]\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
